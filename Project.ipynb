{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from dqn_agent import DQN_Agent\n",
    "from agent_handler import Agent_handler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_env(env: gym.Env):\n",
    "    num_actions = env.action_space.n\n",
    "    obs = env.observation_space\n",
    "    num_obs = env.observation_space.shape\n",
    "\n",
    "    print(\"Observation space: \", obs)\n",
    "    print(\"Observation space size: \", num_obs)\n",
    "    print(\"Number of actions: \", num_actions)\n",
    "\n",
    "    return num_obs, num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results, result_index, window_size, title):\n",
    "  plt.figure(figsize=(25, 10))\n",
    "\n",
    "  for result in results:\n",
    "      sns.lineplot(np.convolve(result[result_index], np.ones(window_size) / window_size, mode='same'), label=f\"(LR, EF) {(result[3]) }\")\n",
    "      \n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = gym.make('MsPacman-v4')\n",
    "\n",
    "num_obs, num_actions = describe_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dqn_agent = DQN_Agent({\n",
    "  \"num_obs\": num_obs,\n",
    "  \"num_actions\": num_actions,\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"discount_factor\": 0.9,\n",
    "  \"exploration_factor\": 0.2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = Agent_handler({\n",
    "    \"num_episodes\":500,\n",
    "    \"max_steps\":1500,\n",
    "    \"notify_percent\":1,\n",
    "    \"update_rate\": 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = handler.train([dqn_agent], env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 1\n",
    "plot(results, 2, smoothing, \"Number of steps per episode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
